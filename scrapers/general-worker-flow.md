# General Worker Flow Documentation

**Complete Pipeline**: `SCRAPE â†’ DETECT_PRICE_CHANGES â†’ SEND_EMAIL`  
**Last Updated**: February 9, 2026  
**Version**: 2.0 (with email notification)

---

## ğŸ¯ Overview

The worker system consists of **3 interconnected workers** that form a complete pipeline from web scraping to email notifications:

1. **Scraper Worker** - Crawl product data from seed banks
2. **Price Detection Worker** - Compare prices and detect significant drops
3. **Email Worker** - Send price alert notifications to users

---

## ğŸ“Š Complete Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PIPELINE OVERVIEW                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  1. SCRAPER WORKER                                                   â”‚
â”‚     â”œâ”€ Parse robots.txt                                             â”‚
â”‚     â”œâ”€ Configure polite crawling                                    â”‚
â”‚     â”œâ”€ Detect pagination (if AUTO mode)                             â”‚
â”‚     â”œâ”€ Crawl pages (respect delays)                                 â”‚
â”‚     â”œâ”€ Extract products from HTML                                   â”‚
â”‚     â”œâ”€ Save to database (upsert)                                    â”‚
â”‚     â””â”€ Emit DETECT_PRICE_CHANGES job                                â”‚
â”‚         â†“                                                            â”‚
â”‚  2. PRICE DETECTION WORKER                                          â”‚
â”‚     â”œâ”€ Load products from job data                                  â”‚
â”‚     â”œâ”€ Query price history from database                            â”‚
â”‚     â”œâ”€ Compare current vs historical prices                         â”‚
â”‚     â”œâ”€ Detect drops â‰¥ 5%                                            â”‚
â”‚     â”œâ”€ Query users with notifications enabled                       â”‚
â”‚     â”œâ”€ Filter users with favorited products                         â”‚
â”‚     â””â”€ Emit SEND_EMAIL jobs (one per user)                          â”‚
â”‚         â†“                                                            â”‚
â”‚  3. EMAIL WORKER (Terminal Step)                                    â”‚
â”‚     â”œâ”€ Receive user info + price changes                            â”‚
â”‚     â”œâ”€ Generate email HTML from template                            â”‚
â”‚     â”œâ”€ Send via Resend API                                          â”‚
â”‚     â””â”€ Log delivery status                                          â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Worker 1: Scraper Worker

### Purpose
Crawl product listings from seed bank websites, extract product data, and save to database.

### Entry Point
- **File**: `lib/workers/scraper.worker.ts`
- **Queue**: `scraper-queue`
- **Processor**: `lib/queue/scraper-queue/scraper.processor.ts`

### Input (Job Data)
```typescript
{
  sellerId: string,           // Seller ID from database
  jobId: string,              // Unique job identifier
  scrapingSources: [{
    scrapingSourceUrl: string,   // Base URL to scrape
    scrapingSourceName: string,  // Scraper identifier (e.g., 'sonomaseeds')
    maxPage: number              // Maximum pages to crawl (fallback)
  }],
  config: {
    mode: 'test' | 'auto',       // TEST (page range) or AUTO (detect pagination)
    startPage?: number,          // TEST mode: start page
    endPage?: number,            // TEST mode: end page
    fullSiteCrawl?: boolean      // AUTO mode: crawl all pages
  }
}
```

### Processing Steps

#### Step 1: Initialization
```typescript
// lib/queue/scraper-queue/scraper.processor.ts

1. Update job status to IN_PROGRESS
2. Initialize SaveDbService with sellerId
3. Load scraper configuration from factory
4. Initialize memory monitoring
```

#### Step 2: Robots.txt Compliance
```typescript
// scrapers/(common)/SimplePoliteCrawler

1. Parse robots.txt from baseUrl
2. Extract crawl delay (default: 10s if specified)
3. Extract disallowed/allowed paths
4. Calculate maxRequestsPerMinute = 60000 / crawlDelay
5. Log compliance strategy
```

#### Step 3: Pagination Detection (AUTO mode only)
```typescript
// scrapers/{seller}/core/{seller}-product-list-scraper.ts

1. Crawl page 1 first
2. Call extractProductsFromHTML()
3. Parse pagination elements:
   - Find .page-numbers or similar selector
   - Extract page numbers from links
   - Use Math.max() to find highest page number
4. Return detected maxPages (or null if not found)
5. Fallback to dbMaxPage if detection fails
```

#### Step 4: Product Crawling
```typescript
// CheerioCrawler requestHandler

FOR EACH PAGE:
  1. Extract products using cheerio selectors
  2. Parse product fields:
     - name, url, slug
     - imageUrl (handle lazy loading)
     - seedType (FEMINIZED, AUTOFLOWER, etc.)
     - cannabisType (Indica, Sativa, Hybrid)
     - THC/CBD levels (min, max)
     - flowering time, growing level
     - pack sizes and pricings
  3. Push products to allProducts array
  4. Track empty pages
  5. Apply polite crawl delay (from robots.txt)
  
  // Progress Logging (AUTO mode, multi-page only)
  IF totalPages > 1:
    progressLogger.shouldLog(pagesProcessed) // Every 10%
    - Log progress percentage
    - Log products collected
    - Log memory status
```

#### Step 5: Database Save
```typescript
// lib/services/db-save-service/SaveDbService

FOR EACH PRODUCT:
  1. Transform to database schema
  2. Upsert SeedProduct (by slug + sellerId)
  3. Upsert ProductImages
  4. Upsert Pricings (by packSize)
  5. Save PriceHistory for tracking
  
RETURN:
  - saved: count of new products
  - updated: count of existing products updated
  - errors: count of save failures
```

#### Step 6: Memory Cleanup
```typescript
// lib/utils/memory-cleanup.ts

1. Log memory before cleanup
2. Clear products array
3. Call global.gc() if available
4. Log memory after cleanup
5. Calculate memory freed
```

### Output (Return Value)
```typescript
{
  totalProducts: number,     // Total products scraped
  totalPages: number,        // Total pages crawled
  saved: number,            // New products saved
  updated: number,          // Existing products updated
  errors: number,           // Save errors
  duration: number          // Milliseconds
}
```

### Next Action
**Emit DETECT_PRICE_CHANGES job** with:
```typescript
{
  sellerId: string,
  sellerName: string,
  seedIds: string[]  // Array of product IDs from scraping
}
```

---

## ğŸ” Worker 2: Price Detection Worker

### Purpose
Compare current prices with historical data, detect significant drops (â‰¥5%), and identify users to notify.

### Entry Point
- **File**: `lib/workers/detect-price-changes.worker.ts`
- **Queue**: `detect-price-changes-queue`
- **Processor**: `lib/queue/detect-price-changes/detect-price-changes.processor.ts`

### Input (Job Data)
```typescript
{
  sellerId: string,      // Seller ID
  sellerName: string,    // Seller identifier (e.g., 'sonomaseeds')
  seedIds: string[]      // Array of product IDs to check
}
```

### Processing Steps

#### Step 1: Load Products & Price History
```typescript
// lib/services/price-alert/detectPriceChanges.ts

1. Query SeedProduct by seedIds
2. Include current pricings (packSize, totalPrice, pricePerSeed)
3. Query PriceHistory for each pricing:
   - Order by createdAt DESC
   - Take 2 most recent (current + previous)
4. Filter out products without pricing history
```

#### Step 2: Detect Price Changes
```typescript
// For each product pricing:

1. Get current price (most recent)
2. Get previous price (second most recent)
3. Calculate price change:
   - priceChange = previousPrice - currentPrice
   - percentChange = (priceChange / previousPrice) Ã— 100
   
4. IF percentChange >= 5%:
   - Create PriceChange object:
     {
       productId: string,
       productName: string,
       productSlug: string,
       productImage: string,
       packSize: number,
       oldPrice: number,
       newPrice: number,
       priceChange: number,
       priceChangePercent: number,
       currency: 'CAD',
       detectedAt: Date
     }
   - Add to changes array
   
5. Log detection summary:
   - totalProducts
   - totalPricingsChecked
   - pricingsWithoutHistory
   - changesDetected
```

#### Step 3: Find Users to Notify
```typescript
// lib/services/price-alert/detectPriceChanges.ts -> findUsersToNotify()

1. Query User table with conditions:
   WHERE:
     - notificationPreference.receivePriceAlerts = true
     - wishlist.some(item => item.seedId IN seedIds)
   
2. Include wishlist items (only favorited products with price drops)
3. Include product images (first image only)

4. Transform to UserWithFavouriteSeeds:
   {
     userId: string,
     email: string,
     name: string,
     favouriteSeeds: [{
       id: string,
       name: string,
       slug: string,
       image: string
     }]
   }
```

#### Step 4: Prepare User-Specific Data
```typescript
// Filter price changes per user

FOR EACH USER:
  1. Filter price changes where productId matches user's favorites
  2. Create user-specific data:
     {
       userId: string,
       email: string,
       userName: string,
       priceChanges: PriceChange[] // Only user's favorited products
     }
  3. Skip users with 0 matching price changes
```

#### Step 5: Create Email Jobs (Batch)
```typescript
// lib/queue/send-price-alert/send-price-alert.jobs.ts

1. Call batchCreatePriceAlertEmailJobs(usersWithChanges)
2. For each user, add job to send-price-alert-queue:
   {
     userId: string,
     email: string,
     userName: string,
     priceChanges: PriceChange[]
   }
3. Return array of job IDs
```

#### Step 6: Memory Cleanup
```typescript
// lib/utils/memory-cleanup.ts

1. Log memory before cleanup
2. Clear local data structures:
   - priceChanges array
   - usersToNotify array
   - usersWithChanges array
3. Call global.gc() if available
4. Log memory after cleanup
5. Calculate memory freed
```

### Output (Return Value)
```typescript
{
  priceChangesDetected: number,   // Total price drops found
  usersToNotify: number,          // Users with matching favorites
  emailJobsCreated: number        // Email jobs emitted
}
```

### Next Action
**Emit SEND_EMAIL jobs** (one per user) with:
```typescript
{
  userId: string,
  email: string,
  userName: string,
  priceChanges: [{
    productId: string,
    productName: string,
    productSlug: string,
    productImage: string,
    packSize: number,
    oldPrice: number,
    newPrice: number,
    priceChange: number,
    priceChangePercent: number,
    currency: string,
    detectedAt: Date
  }]
}
```

---

## ğŸ“§ Worker 3: Email Worker (Terminal Step)

### Purpose
Send price alert email notifications to individual users about their favorited products with price drops.

### Entry Point
- **File**: `lib/workers/send-price-alert.worker.ts`
- **Queue**: `send-price-alert-queue`
- **Processor**: `lib/queue/send-price-alert/send-price-alert.processor.ts`

### Input (Job Data)
```typescript
{
  userId: string,           // User ID for unsubscribe URL
  email: string,            // Recipient email
  userName: string,         // Recipient name for personalization
  priceChanges: [{
    productId: string,
    productName: string,
    productSlug: string,
    productImage: string,
    packSize: number,
    oldPrice: number,
    newPrice: number,
    priceChange: number,        // Absolute amount saved
    priceChangePercent: number, // Percentage discount
    currency: string,           // 'CAD'
    detectedAt: Date
  }]
}
```

### Processing Steps

#### Step 1: Generate Unsubscribe URL
```typescript
// Create unsubscribe link for user preferences

const unsubscribeUrl = `${process.env.NEXT_PUBLIC_APP_URL}/dashboard/settings?tab=notifications&userId=${userId}`;

// Example: https://goodseed.vercel.app/dashboard/settings?tab=notifications&userId=abc123
```

#### Step 2: Prepare Email Content
```typescript
// lib/email-templates/PriceAlertEmail.tsx (React Email)

SUBJECT: 
  "ğŸ”¥ Price Drop Alert! {count} Product{s} on Sale"
  
FROM:
  "Goodseed Price Alerts <noreply@lembooking.com>"
  
TO:
  user.email
  
TEMPLATE DATA:
  {
    userName: string,          // "Hi John" or "Hi there"
    priceChanges: [],         // Array of products with drops
    unsubscribeUrl: string    // Link to manage notifications
  }

EMAIL STRUCTURE:
  1. Greeting: "Hi {userName}!"
  2. Alert message: "Great news! Products in your wishlist are on sale:"
  3. Product cards (for each product):
     - Product image
     - Product name (link to product page)
     - Pack size info
     - Price comparison:
       * Old price (strikethrough)
       * New price (highlighted)
       * Discount badge: "-{percent}%" or "Save ${amount}"
  4. CTA button: "View All Deals"
  5. Footer:
     - Unsubscribe link
     - Company info
```

#### Step 3: Send via Resend API
```typescript
// lib/queue/send-price-alert/send-price-alert.processor.ts

1. Initialize Resend client with API key
2. Call resend.emails.send():
   {
     from: 'Goodseed Price Alerts <noreply@lembooking.com>',
     to: [user.email],
     subject: dynamicSubject,
     react: PriceAlertEmail(data)
   }
3. Handle response:
   - data.id = messageId (for tracking)
   - error = API error details
```

#### Step 4: Log Delivery Status
```typescript
// Success logging
apiLogger.info('[Send Price Alert Processor] Email sent successfully', {
  jobId: job.id,
  userId: userId,
  email: email,
  messageId: data?.id,
  productsCount: priceChanges.length
});

// Error logging (if send fails)
apiLogger.logError('[Send Price Alert Processor] Failed to send email', error, {
  jobId: job.id,
  userId: userId,
  email: email
});
```

### Output (Return Value)
```typescript
{
  emailSent: boolean,          // true if successful
  messageId: string,           // Resend message ID (for tracking)
  recipientEmail: string,      // Confirmation of recipient
  priceChangesCount: number    // Number of products in email
}
```

### User Notification Conditions
Email is sent to a user ONLY IF:
1. âœ… User has `notificationPreference.receivePriceAlerts = true`
2. âœ… User has at least 1 product in wishlist
3. âœ… Wishlist product has a price drop â‰¥ 5%
4. âœ… Product has price history (not first-time scrape)

### Email Content Example
```
Subject: ğŸ”¥ Price Drop Alert! 3 Products on Sale

Hi John!

Great news! Products in your wishlist are on sale:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Product Image]                              â”‚
â”‚ 10th Planet Strain Feminized Seeds          â”‚
â”‚ Pack Size: 5 seeds                          â”‚
â”‚ Was: $65.00  NOW: $55.00                    â”‚
â”‚ [Save $10.00 (-15.4%)]                      â”‚
â”‚ [View Product â†’]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Product Image]                              â”‚
â”‚ 2090 Strain Feminized Seeds                 â”‚
â”‚ Pack Size: 10 seeds                         â”‚
â”‚ Was: $120.00  NOW: $108.00                  â”‚
â”‚ [Save $12.00 (-10.0%)]                      â”‚
â”‚ [View Product â†’]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[View All Deals]

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Don't want these emails? Manage your notification preferences
Â© 2026 Goodseed. All rights reserved.
```

### Next Action
**TERMINAL STEP** - No further jobs emitted. Pipeline ends here.

---

## ğŸ”„ Pipeline State Diagram

```
[Scraper Job Created]
        â†“
[Status: PENDING]
        â†“
[Scraper Worker Picks Up Job]
        â†“
[Status: IN_PROGRESS]
        â†“
[Robots.txt Parsed] â†’ [Memory Monitor Started]
        â†“
[Pagination Detected (AUTO) / Page Range Set (TEST)]
        â†“
[Pages Crawled] â†’ [Products Extracted]
        â†“
[Database Save] â†’ [Price History Recorded]
        â†“
[Status: COMPLETED]
        â†“
[Emit: DETECT_PRICE_CHANGES Job]
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Price Detection Worker            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Load Products + Price History]   â”‚
â”‚         â†“                         â”‚
â”‚ [Compare Prices]                  â”‚
â”‚         â†“                         â”‚
â”‚ [IF Drop â‰¥ 5%]                    â”‚
â”‚         â†“                         â”‚
â”‚ [Query Users with Notifications]  â”‚
â”‚         â†“                         â”‚
â”‚ [Filter Users with Favorites]     â”‚
â”‚         â†“                         â”‚
â”‚ [Prepare User-Specific Data]      â”‚
â”‚         â†“                         â”‚
â”‚ [Emit: SEND_EMAIL Jobs (Batch)]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Email Worker (Per User)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Generate Unsubscribe URL]        â”‚
â”‚         â†“                         â”‚
â”‚ [Render Email Template]           â”‚
â”‚         â†“                         â”‚
â”‚ [Send via Resend API]             â”‚
â”‚         â†“                         â”‚
â”‚ [Log Delivery Status]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
[Pipeline Complete]
```

---

## ğŸ“Š Logging Strategy

### Scraper Worker Logs
```typescript
// Milestone-based logging (no per-page verbose logs)

[INFO] Starting scraper (mode, pages, config)
[INFO] Robots.txt compliance (delay, paths)
[INFO] Memory configuration (limit, thresholds)
[INFO] Crawler configuration (rate, concurrency)
[INFO] Pagination detected (maxPages from HTML) // AUTO mode only
[CRAWL] Progress Update (10%, 20%, 30%...) // AUTO mode, multi-page only
[CRAWL] Crawling completed (products, pages, duration, memory)
[DEBUG] Sample products data (first 3 products)
[DEBUG] Products saved (saved, updated, errors)
[INFO] Price detection job emitted (productCount)
[DEBUG] Memory cleanup (before, after, freed)
```

### Price Detection Worker Logs
```typescript
[INFO] Processing seller (jobId, sellerId, sellerName, productCount)
[INFO] Detecting price changes (jobId, sellerId, seedCount)
[INFO] Price change detection complete (total, checked, changesDetected)
[INFO] Price drop detected (product, packSize, oldPrice, newPrice, percent) // Per product
[INFO] Creating email jobs (jobId, usersCount)
[INFO] Completed (priceChanges, usersToNotify, emailJobsCreated)
```

### Email Worker Logs
```typescript
[INFO] Sending email (jobId, userId, email, changesCount)
[INFO] Email sent successfully (jobId, userId, messageId, productsCount)
[ERROR] Failed to send email (jobId, userId, email, error)
```

---

## ğŸ›¡ï¸ Error Handling

### Scraper Worker Errors
```typescript
TRY:
  - Parse robots.txt
  - Crawl pages
  - Extract products
  - Save to database
CATCH:
  - Log error with context
  - Update job status to FAILED
  - Throw error (Bull retry)
  - DO NOT emit price detection job
```

### Price Detection Worker Errors
```typescript
TRY:
  - Load products
  - Detect price changes
  - Query users
  - Create email jobs
  - Memory cleanup (always executed)
CATCH:
  - Log error with context
  - Throw error (Bull retry)
  - Partial jobs may be created (idempotent)
  - Memory cleanup still attempted (non-blocking)
```

### Email Worker Errors
```typescript
TRY:
  - Generate email
  - Send via Resend
CATCH:
  - Log error with user context
  - Throw error (Bull retry up to 3 times)
  - DO NOT block other email jobs
```

---

## ğŸš€ Performance Optimizations

### Memory Management
- **Environment-based config**: Read `WORKER_MEMORY_LIMIT_MB` from env
- **Progress-based monitoring**: Track memory at 10% intervals
- **Post-job cleanup**: Free ~20-30MB after each job
- **GC trigger**: Call `global.gc()` if available

### Logging Efficiency
- **Milestone-based**: Log every 10% instead of per-page
- **Batch operations**: Reduce log buffer accumulation
- **Result**: ~95% fewer logs (800 â†’ ~10 per job)

### Database Operations
- **Upsert**: Avoid duplicate checks
- **Batch processing**: Save multiple products in transaction
- **Selective queries**: Only load necessary fields

### Email Delivery
- **Batch job creation**: Create all email jobs at once
- **Async processing**: Multiple emails sent in parallel
- **Retry logic**: Bull handles retries automatically

---

## ğŸ“‹ Testing Checklist

### Scraper Worker
- [x] TEST mode crawls specific page range
- [x] AUTO mode detects pagination correctly
- [x] Robots.txt compliance enforced
- [x] Memory stays below warning threshold
- [x] Products saved with 0 errors
- [x] Price detection job emitted
- [x] Memory cleanup after job

### Price Detection Worker
- [x] Loads products with price history
- [x] Detects drops â‰¥ 5% accurately
- [x] Queries users with notifications enabled
- [x] Filters users with matching favorites
- [x] Creates email jobs (one per user)
- [x] Handles 0 changes gracefully
- [ ] Memory cleanup after job completion

### Email Worker
- [ ] Generates correct email content
- [ ] Sends via Resend successfully
- [ ] Unsubscribe URL works
- [ ] Email template renders correctly
- [ ] Retry logic works on failures
- [ ] Logs delivery status

---

## ğŸ”— Related Files

### Scraper Worker
- `lib/workers/scraper.worker.ts` - Worker initialization
- `lib/queue/scraper-queue/scraper.processor.ts` - Job processor
- `scrapers/{seller}/core/{seller}-product-list-scraper.ts` - Scraper logic
- `lib/services/db-save-service/SaveDbService.ts` - Database operations

### Price Detection Worker
- `lib/workers/detect-price-changes.worker.ts` - Worker initialization
- `lib/queue/detect-price-changes/detect-price-changes.processor.ts` - Job processor
- `lib/services/price-alert/detectPriceChanges.ts` - Price comparison logic

### Email Worker
- `lib/workers/send-price-alert.worker.ts` - Worker initialization
- `lib/queue/send-price-alert/send-price-alert.processor.ts` - Email sending
- `lib/email-templates/PriceAlertEmail.tsx` - Email template (React Email)

### Supporting Files
- `lib/config/worker-memory.config.ts` - Memory configuration
- `lib/utils/memory-cleanup.ts` - Memory cleanup utilities
- `scrapers/(common)/logging-helpers.ts` - ProgressLogger, MemoryMonitor
- `lib/helpers/api-logger.ts` - Logging utilities

---

## ğŸ“ Environment Variables

```bash
# Worker Configuration
WORKER_MEMORY_LIMIT_MB=1536              # Memory limit in MB
WORKER_MEMORY_WARNING_THRESHOLD=0.80     # Warning at 80%
WORKER_MEMORY_CRITICAL_THRESHOLD=0.90    # Critical at 90%

# Email Configuration
RESEND_API_KEY=re_xxxxxxxxxxxxx          # Resend API key
RESEND_FROM_EMAIL=noreply@lembooking.com # Sender email
NEXT_PUBLIC_APP_URL=https://goodseed.vercel.app # App URL for links

# Redis (Bull Queue)
REDIS_URL=redis://localhost:6379         # Redis connection
```

---

**Last Review**: February 9, 2026  
**Status**: âœ… Production Ready  
**Version**: 2.0 - Complete pipeline with email notifications
