FROM node:20-alpine

# Install only required dependencies for Crawlee + Cheerio
# Note: Chromium is NOT needed since we use CheerioCrawler (HTML parsing only)
RUN apk add --no-cache \
    ca-certificates

# Set working directory
WORKDIR /app

# Install pnpm
RUN npm install -g pnpm

# Copy dependency files
COPY package.json pnpm-lock.yaml ./

# Copy Prisma schema BEFORE installing dependencies
# (needed for postinstall prisma generate)
COPY prisma ./prisma

# Install dependencies (will run prisma generate in postinstall)
RUN pnpm install --frozen-lockfile

# Copy application code
COPY . .

# Expose health check port
EXPOSE 3001

# Add health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
  CMD node -e "require('http').get('http://localhost:3001/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)}).on('error', () => process.exit(1))"

# Set Node.js memory limit to 1536MB (safe for 2GB container on Render Standard)
# TESTING: Increased from 400MB â†’ 1536MB to validate memory bottleneck hypothesis
# This prevents Out of Memory errors when scraping large sites
# Note: Render Standard has 2GB total RAM, leave ~500MB for system overhead
# Original: 400MB for Starter (512MB total)
# --expose-gc enables manual garbage collection for cleanup after jobs
ENV NODE_OPTIONS="--max-old-space-size=1536 --expose-gc"

# Scraper logging control - set to 'true' to enable detailed crawl logs for debugging
# Default: false in production to prevent memory leaks from excessive logging
ENV ENABLE_CRAWL_LOGS=true

# Start unified worker (handles scraper, price-alert, and future job types)
CMD ["pnpm", "run", "worker"]
